{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection from Credit Card History, Machine learning algorithms\n",
    "The following jupyter notebook contains a binary classification for fraud detection, from a credit card history. For this; we are gonna explore the following three machine learning algorithms:\n",
    "* Logistic Regression\n",
    "* Decition Tree\n",
    "* Linear Support Vector Machine\n",
    "\n",
    "This jupyter notebook would showcase the following:\n",
    "1. Confusion matrix for each of the models\n",
    "2. Cross validation metrics (precision, recall, f1_score, accuracy_score).\n",
    "3. Plot of probability distributions between real test data vs each models predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "# Get the root project path\n",
    "root_project_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "#Append it to sys\n",
    "sys.path.append(root_project_path)\n",
    "\n",
    "#Import the necessary modules\n",
    "from utils import DataLoader, CreditCardPreprocesser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the folder name and data folder\n",
    "folder_name = \"data\"\n",
    "data_holder_path = os.path.join(os.getcwd(), os.pardir)\n",
    "\n",
    "#Set the folder name\n",
    "data_loader = DataLoader(data_folder_name=folder_name,\\\n",
    "    data_folder_path=data_holder_path)\n",
    "\n",
    "#Get the data\n",
    "df_data = data_loader.get_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the preprocessed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an instance of the Credit card processer\n",
    "credit_card_processer = CreditCardPreprocesser(df_data=df_data)\n",
    "\n",
    "#Obtain the df_preprocessed\n",
    "df_preprocessed = credit_card_processer.fetch_preprocessed_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1296675, 96)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 96 columns):\n",
      " #   Column                   Non-Null Count    Dtype  \n",
      "---  ------                   --------------    -----  \n",
      " 0   cc_num                   1296675 non-null  int64  \n",
      " 1   amt                      1296675 non-null  float64\n",
      " 2   gender                   1296675 non-null  int64  \n",
      " 3   zip                      1296675 non-null  int64  \n",
      " 4   lat                      1296675 non-null  float64\n",
      " 5   long                     1296675 non-null  float64\n",
      " 6   city_pop                 1296675 non-null  int64  \n",
      " 7   unix_time                1296675 non-null  int64  \n",
      " 8   merch_lat                1296675 non-null  float64\n",
      " 9   merch_long               1296675 non-null  float64\n",
      " 10  is_fraud                 1296675 non-null  int64  \n",
      " 11  merch_zipcode            1296675 non-null  float64\n",
      " 12  transaction_year         1296675 non-null  int32  \n",
      " 13  transaction_month        1296675 non-null  int32  \n",
      " 14  transaction_day          1296675 non-null  int32  \n",
      " 15  transaction_hour         1296675 non-null  int32  \n",
      " 16  transaction_minute       1296675 non-null  int32  \n",
      " 17  transaction_second       1296675 non-null  int32  \n",
      " 18  birth_year               1296675 non-null  int32  \n",
      " 19  birth_month              1296675 non-null  int32  \n",
      " 20  birth_day                1296675 non-null  int32  \n",
      " 21  category_food_dining     1296675 non-null  int32  \n",
      " 22  category_gas_transport   1296675 non-null  int32  \n",
      " 23  category_grocery_net     1296675 non-null  int32  \n",
      " 24  category_grocery_pos     1296675 non-null  int32  \n",
      " 25  category_health_fitness  1296675 non-null  int32  \n",
      " 26  category_home            1296675 non-null  int32  \n",
      " 27  category_kids_pets       1296675 non-null  int32  \n",
      " 28  category_misc_net        1296675 non-null  int32  \n",
      " 29  category_misc_pos        1296675 non-null  int32  \n",
      " 30  category_personal_care   1296675 non-null  int32  \n",
      " 31  category_shopping_net    1296675 non-null  int32  \n",
      " 32  category_shopping_pos    1296675 non-null  int32  \n",
      " 33  category_travel          1296675 non-null  int32  \n",
      " 34  state_AL                 1296675 non-null  int32  \n",
      " 35  state_AR                 1296675 non-null  int32  \n",
      " 36  state_AZ                 1296675 non-null  int32  \n",
      " 37  state_CA                 1296675 non-null  int32  \n",
      " 38  state_CO                 1296675 non-null  int32  \n",
      " 39  state_CT                 1296675 non-null  int32  \n",
      " 40  state_DC                 1296675 non-null  int32  \n",
      " 41  state_DE                 1296675 non-null  int32  \n",
      " 42  state_FL                 1296675 non-null  int32  \n",
      " 43  state_GA                 1296675 non-null  int32  \n",
      " 44  state_HI                 1296675 non-null  int32  \n",
      " 45  state_IA                 1296675 non-null  int32  \n",
      " 46  state_ID                 1296675 non-null  int32  \n",
      " 47  state_IL                 1296675 non-null  int32  \n",
      " 48  state_IN                 1296675 non-null  int32  \n",
      " 49  state_KS                 1296675 non-null  int32  \n",
      " 50  state_KY                 1296675 non-null  int32  \n",
      " 51  state_LA                 1296675 non-null  int32  \n",
      " 52  state_MA                 1296675 non-null  int32  \n",
      " 53  state_MD                 1296675 non-null  int32  \n",
      " 54  state_ME                 1296675 non-null  int32  \n",
      " 55  state_MI                 1296675 non-null  int32  \n",
      " 56  state_MN                 1296675 non-null  int32  \n",
      " 57  state_MO                 1296675 non-null  int32  \n",
      " 58  state_MS                 1296675 non-null  int32  \n",
      " 59  state_MT                 1296675 non-null  int32  \n",
      " 60  state_NC                 1296675 non-null  int32  \n",
      " 61  state_ND                 1296675 non-null  int32  \n",
      " 62  state_NE                 1296675 non-null  int32  \n",
      " 63  state_NH                 1296675 non-null  int32  \n",
      " 64  state_NJ                 1296675 non-null  int32  \n",
      " 65  state_NM                 1296675 non-null  int32  \n",
      " 66  state_NV                 1296675 non-null  int32  \n",
      " 67  state_NY                 1296675 non-null  int32  \n",
      " 68  state_OH                 1296675 non-null  int32  \n",
      " 69  state_OK                 1296675 non-null  int32  \n",
      " 70  state_OR                 1296675 non-null  int32  \n",
      " 71  state_PA                 1296675 non-null  int32  \n",
      " 72  state_RI                 1296675 non-null  int32  \n",
      " 73  state_SC                 1296675 non-null  int32  \n",
      " 74  state_SD                 1296675 non-null  int32  \n",
      " 75  state_TN                 1296675 non-null  int32  \n",
      " 76  state_TX                 1296675 non-null  int32  \n",
      " 77  state_UT                 1296675 non-null  int32  \n",
      " 78  state_VA                 1296675 non-null  int32  \n",
      " 79  state_VT                 1296675 non-null  int32  \n",
      " 80  state_WA                 1296675 non-null  int32  \n",
      " 81  state_WI                 1296675 non-null  int32  \n",
      " 82  state_WV                 1296675 non-null  int32  \n",
      " 83  state_WY                 1296675 non-null  int32  \n",
      " 84  merchant_encoded         1296675 non-null  float64\n",
      " 85  merchant_freq            1296675 non-null  int64  \n",
      " 86  first_encoded            1296675 non-null  float64\n",
      " 87  first_freq               1296675 non-null  int64  \n",
      " 88  last_encoded             1296675 non-null  float64\n",
      " 89  last_freq                1296675 non-null  int64  \n",
      " 90  street_encoded           1296675 non-null  float64\n",
      " 91  street_freq              1296675 non-null  int64  \n",
      " 92  city_encoded             1296675 non-null  float64\n",
      " 93  city_freq                1296675 non-null  int64  \n",
      " 94  job_encoded              1296675 non-null  float64\n",
      " 95  job_freq                 1296675 non-null  int64  \n",
      "dtypes: float64(12), int32(72), int64(12)\n",
      "memory usage: 593.6 MB\n"
     ]
    }
   ],
   "source": [
    "df_preprocessed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets select the X and Y target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X: pd.DataFrame = df_preprocessed[[col for col in df_preprocessed.columns if col != \"is_fraud\"]]\n",
    "y: pd.DataFrame = df_preprocessed[\"is_fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_fraud\n",
       "0    1289169\n",
       "1       7506\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets now oversample it using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "\n",
    "#Obtain the over sampled new values\n",
    "X_smote, y_smote = smote.fit_resample(X.astype(\"float\"), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_fraud\n",
       "0    1289169\n",
       "1    1289169\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_smote.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the continous columns:\n",
    "\n",
    "Lets select now the continous columns; where we are gonna apply our `Standardscaler()` instance from scikit-learn to perform standardscaling on ONLY the continous features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List all the continous features\n",
    "continous_features = [\"cc_num\", \"amt\", \"zip\", \"lat\", \"long\", \"city_pop\", \"unix_time\",\\\n",
    "    \"merch_lat\", \"merch_long\", \"merch_zipcode\", \"transaction_year\", \"transaction_month\",\\\n",
    "    \"transaction_day\", \"transaction_hour\", \"transaction_minute\", \"transaction_second\",\\\n",
    "    \"birth_year\", \"birth_month\", \"birth_day\", \"merchant_encoded\", \"merchant_freq\",\\\n",
    "    \"first_encoded\", \"first_freq\", \"last_encoded\", \"last_freq\", \"street_encoded\",\\\n",
    "    \"street_freq\", \"city_encoded\", \"city_freq\", \"job_encoded\", \"job_freq\"]\n",
    "\n",
    "#Select the continous and not continous \n",
    "X_smote_continous = X_smote[continous_features]\n",
    "X_smote_discontinous = X_smote[[c for c in X_smote.columns if c not in continous_features]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>category_food_dining</th>\n",
       "      <th>category_gas_transport</th>\n",
       "      <th>category_grocery_net</th>\n",
       "      <th>category_grocery_pos</th>\n",
       "      <th>category_health_fitness</th>\n",
       "      <th>category_home</th>\n",
       "      <th>category_kids_pets</th>\n",
       "      <th>category_misc_net</th>\n",
       "      <th>category_misc_pos</th>\n",
       "      <th>...</th>\n",
       "      <th>state_SD</th>\n",
       "      <th>state_TN</th>\n",
       "      <th>state_TX</th>\n",
       "      <th>state_UT</th>\n",
       "      <th>state_VA</th>\n",
       "      <th>state_VT</th>\n",
       "      <th>state_WA</th>\n",
       "      <th>state_WI</th>\n",
       "      <th>state_WV</th>\n",
       "      <th>state_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  category_food_dining  category_gas_transport  category_grocery_net  \\\n",
       "0     1.0                   0.0                     0.0                   0.0   \n",
       "1     1.0                   0.0                     0.0                   0.0   \n",
       "2     0.0                   0.0                     0.0                   0.0   \n",
       "\n",
       "   category_grocery_pos  category_health_fitness  category_home  \\\n",
       "0                   0.0                      0.0            0.0   \n",
       "1                   1.0                      0.0            0.0   \n",
       "2                   0.0                      0.0            0.0   \n",
       "\n",
       "   category_kids_pets  category_misc_net  category_misc_pos  ...  state_SD  \\\n",
       "0                 0.0                1.0                0.0  ...       0.0   \n",
       "1                 0.0                0.0                0.0  ...       0.0   \n",
       "2                 0.0                0.0                0.0  ...       0.0   \n",
       "\n",
       "   state_TN  state_TX  state_UT  state_VA  state_VT  state_WA  state_WI  \\\n",
       "0       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1       0.0       0.0       0.0       0.0       0.0       1.0       0.0   \n",
       "2       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   state_WV  state_WY  \n",
       "0       0.0       0.0  \n",
       "1       0.0       0.0  \n",
       "2       0.0       0.0  \n",
       "\n",
       "[3 rows x 64 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_smote_discontinous.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets implement the standardscaler to continous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Create a standard scaler object and fit x_train\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(X_smote_continous)\n",
    "\n",
    "#Transform x_train and x_test\n",
    "X_continous_scaled = standard_scaler.transform(X_smote_continous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets make a pandas dataframe\n",
    "X_continous_scaled = pd.DataFrame(X_continous_scaled,\\\n",
    "    columns=X_smote_continous.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2578338, 31)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_continous_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc_num</th>\n",
       "      <th>amt</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>merch_zipcode</th>\n",
       "      <th>...</th>\n",
       "      <th>first_encoded</th>\n",
       "      <th>first_freq</th>\n",
       "      <th>last_encoded</th>\n",
       "      <th>last_freq</th>\n",
       "      <th>street_encoded</th>\n",
       "      <th>street_freq</th>\n",
       "      <th>city_encoded</th>\n",
       "      <th>city_freq</th>\n",
       "      <th>job_encoded</th>\n",
       "      <th>job_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.314150</td>\n",
       "      <td>-0.848850</td>\n",
       "      <td>-0.731042</td>\n",
       "      <td>-0.491930</td>\n",
       "      <td>0.635041</td>\n",
       "      <td>-0.285663</td>\n",
       "      <td>-1.757352</td>\n",
       "      <td>-0.500967</td>\n",
       "      <td>0.572346</td>\n",
       "      <td>-0.748712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082052</td>\n",
       "      <td>1.394889</td>\n",
       "      <td>-0.301223</td>\n",
       "      <td>-0.634687</td>\n",
       "      <td>-0.348258</td>\n",
       "      <td>0.578768</td>\n",
       "      <td>-0.335356</td>\n",
       "      <td>0.202299</td>\n",
       "      <td>-0.255371</td>\n",
       "      <td>-0.058337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.316239</td>\n",
       "      <td>-0.552402</td>\n",
       "      <td>1.874381</td>\n",
       "      <td>2.008749</td>\n",
       "      <td>-2.006590</td>\n",
       "      <td>-0.296317</td>\n",
       "      <td>-1.757350</td>\n",
       "      <td>2.049103</td>\n",
       "      <td>-2.002685</td>\n",
       "      <td>-0.015102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.200993</td>\n",
       "      <td>0.424524</td>\n",
       "      <td>-0.227082</td>\n",
       "      <td>-0.472404</td>\n",
       "      <td>-0.348258</td>\n",
       "      <td>1.796085</td>\n",
       "      <td>-0.335356</td>\n",
       "      <td>1.622037</td>\n",
       "      <td>-0.243063</td>\n",
       "      <td>0.687720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.316210</td>\n",
       "      <td>-0.225168</td>\n",
       "      <td>1.286529</td>\n",
       "      <td>0.699353</td>\n",
       "      <td>-1.582266</td>\n",
       "      <td>-0.283564</td>\n",
       "      <td>-1.757350</td>\n",
       "      <td>0.883756</td>\n",
       "      <td>-1.572875</td>\n",
       "      <td>1.583230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273950</td>\n",
       "      <td>-0.748839</td>\n",
       "      <td>-0.054494</td>\n",
       "      <td>0.176249</td>\n",
       "      <td>-0.348258</td>\n",
       "      <td>-1.273935</td>\n",
       "      <td>-0.335356</td>\n",
       "      <td>-1.224925</td>\n",
       "      <td>0.114394</td>\n",
       "      <td>-1.514924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cc_num       amt       zip       lat      long  city_pop  unix_time  \\\n",
       "0 -0.314150 -0.848850 -0.731042 -0.491930  0.635041 -0.285663  -1.757352   \n",
       "1 -0.316239 -0.552402  1.874381  2.008749 -2.006590 -0.296317  -1.757350   \n",
       "2 -0.316210 -0.225168  1.286529  0.699353 -1.582266 -0.283564  -1.757350   \n",
       "\n",
       "   merch_lat  merch_long  merch_zipcode  ...  first_encoded  first_freq  \\\n",
       "0  -0.500967    0.572346      -0.748712  ...      -0.082052    1.394889   \n",
       "1   2.049103   -2.002685      -0.015102  ...      -0.200993    0.424524   \n",
       "2   0.883756   -1.572875       1.583230  ...      -0.273950   -0.748839   \n",
       "\n",
       "   last_encoded  last_freq  street_encoded  street_freq  city_encoded  \\\n",
       "0     -0.301223  -0.634687       -0.348258     0.578768     -0.335356   \n",
       "1     -0.227082  -0.472404       -0.348258     1.796085     -0.335356   \n",
       "2     -0.054494   0.176249       -0.348258    -1.273935     -0.335356   \n",
       "\n",
       "   city_freq  job_encoded  job_freq  \n",
       "0   0.202299    -0.255371 -0.058337  \n",
       "1   1.622037    -0.243063  0.687720  \n",
       "2  -1.224925     0.114394 -1.514924  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_continous_scaled.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets create the actual datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the new datasets\n",
    "X_data = pd.concat([X_continous_scaled, X_smote_discontinous], axis=1)\n",
    "y_data = copy.copy(y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2578338, 95)\n",
      "(2578338,)\n"
     ]
    }
   ],
   "source": [
    "#Lets get the shapes\n",
    "print(X_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets initialize the following classifiers\n",
    "Now we are gonna intialize each of the classifiers, and perform cross validation to obtain all of the different metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state = 42, max_iter=1000),\n",
    "    \"Decition Tree Classifier\": DecisionTreeClassifier(random_state = 42),\n",
    "    \"Linear Support Vector Machine\": LinearSVC(C=1.0, max_iter=1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1933753, 95)\n",
      "(644585, 95)\n",
      "(1933753,)\n",
      "(644585,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_data, y_data)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Cross validation for all ML algorithms\n",
    "Lets now perform cross validation for each of the ML algorithms, to obtain its results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========Logistic Regression============ Starting\n",
      "iteration: 0: Logistic Regression\n",
      "iteration: 1: Logistic Regression\n",
      "\n",
      "===========Logistic Regression============ Ending\n",
      "\n",
      "===========Decition Tree Classifier============ Starting\n",
      "iteration: 0: Decition Tree Classifier\n",
      "iteration: 1: Decition Tree Classifier\n",
      "\n",
      "===========Decition Tree Classifier============ Ending\n",
      "\n",
      "===========Linear Support Vector Machine============ Starting\n",
      "iteration: 0: Linear Support Vector Machine\n",
      "iteration: 1: Linear Support Vector Machine\n",
      "\n",
      "===========Linear Support Vector Machine============ Ending\n"
     ]
    }
   ],
   "source": [
    "#Lets create the holders for each metrics\n",
    "ml_metrics = {}\n",
    "\n",
    "for name, clf in ml_classifiers.items():\n",
    "    print(f\"\\n==========={name}============ Starting\")\n",
    "    #Lets initialize variables for each\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    # Lets write a fot loop that goes 20 times\n",
    "    for i in range(20):\n",
    "        print(f\"iteration: {i}: {name}\")\n",
    "        #Call the train test split\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X_data, y_data)\n",
    "\n",
    "        #Lets fit each of the classifiers\n",
    "        clf.fit(X=x_train, y=y_train)\n",
    "\n",
    "        #Obtain the predictions for both\n",
    "        y_pred = clf.predict(x_test)\n",
    "\n",
    "        #Lets append them\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        precisions.append(precision_score(y_test, y_pred))\n",
    "        recalls.append(recall_score(y_test, y_pred))\n",
    "        f1_scores.append(f1_score(y_test, y_pred))\n",
    "\n",
    "    #Lets add the metrics\n",
    "    ml_metrics[name + \"_accuracies\"] = accuracies\n",
    "    ml_metrics[name + \"_precisions\"] = precisions\n",
    "    ml_metrics[name + \"_recalls\"] = recalls\n",
    "    ml_metrics[name + \"_f1_scores\"] = f1_scores\n",
    "\n",
    "    #Create a dataframe and save it into a dataframe\n",
    "    df_results = pd.DataFrame(ml_metrics)\n",
    "    df_results.to_csv('my_data_' + name + '.csv', index=False)\n",
    "    print(f\"\\n==========={name}============ Ending\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
